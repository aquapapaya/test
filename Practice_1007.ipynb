{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先設定batch size跟numworker\n",
    "batch_size = 32\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "關於transforms.Resize，要注意的是她剪出來不是正方形，而是图像较小的边缘将被匹配到该数字. 例如, 如果 height > width, 那么图像将会被重新缩放到 (size * height / width, size). 即按照size/width的比值缩放\n",
    "\n",
    "而transforms.CenterCrop，裁剪出来的图像是 (size, size) 这样的正方形的.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=os.path.join('datasets','keras')\n",
    "traindir=os.path.join(data_dir,'train')\n",
    "valdir=os.path.join(data_dir,'val')\n",
    "testdir=os.path.join(data_dir,'test')\n",
    "\n",
    "normolize=transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "       transforms.Resize(256),\n",
    "       transforms.CenterCrop(224),\n",
    "       transforms.ToTensor(),\n",
    "       normolize,\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整理总结\n",
    "我们来整理一下整个实现思路哦～\n",
    "主要分以下三种情况：\n",
    "\n",
    "### 1 对于torchvision提供的数据集\n",
    "这是最简单的一种情况。\n",
    "对于这一类数据集，就是PyTorch已经帮我们做好了所有的事情，连数据源都不需要自己下载。\n",
    "Imagenet，CIFAR10，MNIST等等PyTorch都提供了数据加载的功能，所以可以先看看你要用的数据集是不是这种情况。\n",
    "具体的使用方法详见之前的博客Pytorch入门学习（四）－training a classifier\n",
    "### 2 对于特定结构的数据集\n",
    "这种情况就是不在上述PyTorch提供数据库之列，但是满足下面的形式：\n",
    " root/ants/xxx.png\n",
    " root/ants/xxy.jpeg\n",
    " root/ants/xxz.png\n",
    ".\n",
    ".\n",
    ".\n",
    "root/bees/123.jpg\n",
    "root/bees/nsdf3.png\n",
    "root/bees/asd932_.png\n",
    "那么就可以通过torchvision中的通用数据集ImageFolder来完成加载。\n",
    "具体使用方法见上文。\n",
    "### 3 对于最普通的数据集\n",
    "最后一种情况是既不是自带数据集，又不满足ImageFolder,这种时候就自己进行处理。\n",
    "首先，定义数据集的类（myDataset），这个类要继承dataset这个抽象类，并实现__len__以及__getitem__这两个函数，通常情况还包括初始函数__init__.\n",
    "然后，实现用于特定图像预处理的功能，并封装成类。当然常用的一些变换可以在torchvision中找到。用torchvision.transforms.Compose将它们进行组合成(transform)\n",
    "transform作为上面myDataset类的参数传入，并得到实例化myDataset得到（transformed_dataset）对象。\n",
    "最后，将transformed_dataset作为torch.utils.data.DataLoader类的形参，并根据需求设置自己是否需要打乱顺序，批大小...\n",
    "链接：https://www.jianshu.com/p/6e22d21c84be\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_loader= torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(traindir,transforms.Compose(\n",
    "        [transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normolize,]\n",
    "    )),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "val_loader= torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir,transforms.Compose(\n",
    "        [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normolize,]\n",
    "    )),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(testdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normolize,\n",
    "    ])),\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "\n",
    "\n",
    "classes=[d for d in os.listdir(traindir) if os.path.isdir(os.path.join(traindir,d))]\n",
    "classes.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp():\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%m-%d_%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "關於model.train()，有兩種方法可以讓模型知道您的意圖，即您是想訓練模型還是想要使用模型進行評估。在model.train（）的情況下，模型知道它必須學習層，當我們使用model.eval（）時，它表示模型沒有新的東西要學習，模型用於測試。\n",
    "\n",
    "關於cuda()，通常只有要訓練的Tensor跟model才會需要cuda\n",
    "\n",
    "score的size是(batch,class的數目) # (32,2)\n",
    "torch.max()返回两个结果，第一个是最大值，第二个是对应的索引值；第二个参数 0 代表按列取最大值并返回对应的行索引值，1 代表按行取最大值并返回对应的列索引值。\n",
    "squeeze中的参数0、1分别代表第一、第二维度，squeeze(0)表示如果第一维度值为1，则去掉，否则不变。故b的维度(1,3),可去掉1成(3),但不可去掉3。\n",
    "參考: http://milletpu.com/2018/04/07/pytorch-view/\n",
    "\n",
    "我们需要关注的是一開始import 的 autograd.Variable。这个东西包装了Tensor。Variable有一个名叫data的字段，可以通过它获得被包装起来的那个原始的Tensor数据。也就是varialbe.data 的類型是tensor。\n",
    "最後可以用variable.data.numpy()轉成numpy 形式\n",
    "另外也可以使用detach()，因為在requires_grad =True時使用data的話，其值可能會被修改掉!\n",
    "至於要取出tensor的值 可以直接印，或者後面接.data都可以\n",
    "唯一要注意的就是，當tensor的維度是0，也就是一個值，則直接用.item()，例如loss就是一個值來累加，此時用item()即可\n",
    "參閱: https://zhuanlan.zhihu.com/p/36307662\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader,val_loader, loss_fn, optimizer, num_epochs=1):\n",
    "    start_time = time.time()\n",
    "    timestamp = get_timestamp()\n",
    "    tloss_plot=[]\n",
    "    tacc_plot=[]\n",
    "    vloss_plot=[]\n",
    "    vacc_plot=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Starting epoch %d /%d\" % (epoch, num_epochs))\n",
    "        model.train()\n",
    "        batch_start=time.time()\n",
    "        for t, (x,y) in enumerate(train_loader):\n",
    "            \n",
    "            train_num_correct = 0\n",
    "            train_num_samples = 0\n",
    "            val_num_correct = 0\n",
    "            val_num_samples = 0\n",
    "            x_var=x.cuda()\n",
    "            y_var=y.cuda()\n",
    "            score=model(x_var)\n",
    "            loss=loss_fn(score,y_var)\n",
    "            \n",
    "            if (t+1)%10==0:\n",
    "                print('t=%d, loss=%.4f, duration= %s' % (t + 1, loss.item(), timedelta(seconds=time.time() - batch_start)))\n",
    "                \n",
    "                _, preds = score.detach().cuda().max(1)\n",
    "                #       preds = torch.max(score, 1)[1].cuda().detach.squeeze() \n",
    "                train_num_correct += (preds == y_var).sum()\n",
    "            \n",
    "                train_num_samples += preds.size(0) #就是取第一個維度的size\n",
    "                acc = float(train_num_correct) / train_num_samples\n",
    "                print('train: Got %d / %d correct (%.2f)' % (train_num_correct, train_num_samples, 100 * acc))\n",
    "                tloss_plot.append(loss.item())\n",
    "                tacc_plot.append(acc)\n",
    "                \n",
    "                \n",
    "                val_x, val_y= next(iter(val_loader))\n",
    "                val_x = val_x.cuda()\n",
    "                val_y = val_y.cuda()\n",
    "                score_val=model(val_x)\n",
    "                val_loss=loss_fn(score_val,val_y)\n",
    "                _, preds_val = score_val.detach().cuda().max(1)\n",
    "                val_num_correct += (preds_val == val_y).sum()\n",
    "                val_num_samples += preds_val.size(0) #就是取第一個維度的size\n",
    "                val_acc = float(val_num_correct) / val_num_samples\n",
    "\n",
    "                print('val: Got %d / %d correct (%.2f)' % (val_num_correct, val_num_samples, 100 * val_acc))\n",
    "                vloss_plot.append(val_loss.item())\n",
    "                vacc_plot.append(val_acc)\n",
    "                \n",
    "                batch_start=time.time()\n",
    "                \n",
    "                \n",
    "            optimizer.zero_grad()# clear gradients for next train\n",
    "            loss.backward() # backpropagation, compute gradients\n",
    "            optimizer.step() # apply gradients\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "    save_path = './ckpt'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "    torch.save(model.state_dict(), save_path+'/model.ckpt')\n",
    "    torch.save(optimizer.state_dict(), save_path+'/ts.ckpt')\n",
    "    \n",
    "    \n",
    "    print('duration = %s' % timedelta(seconds=time.time() - start_time))    \n",
    "    plt.plot(tloss_plot, '-b',label='train_Loss')\n",
    "    plt.plot(vloss_plot, '-r',label='val_Loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.plot(tacc_plot, '-b',label='train_acc')\n",
    "    plt.plot(vacc_plot, '-r',label='val_acc')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('acc')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解說:\n",
    "I want to use the VGG19 in my own dataset, which has 8 classes.Ｓo I want to change the output of the last fc layer to 8. So what should I do to change the last fc layer to fit it.\n",
    "----\n",
    "model = torchvision.models.vgg19(pretrained=True)\n",
    "for param in model.parameters():\n",
    "\n",
    "    param.requires_grad = False\n",
    "    \n",
    "    # Replace the last fully-connected layer\n",
    "    # Parameters of newly constructed modules have requires_grad=True by default\n",
    "model.fc = nn.Linear(512, 8)  # assuming that the fc7 layer has 512 neurons, \n",
    "otherwise change it \n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet34(pretrained=True):\n",
    "    model = models.resnet34(pretrained=pretrained)\n",
    "    def set_untrainable(layer):\n",
    "        for p in layer.parameters():\n",
    "             p.requires_grad = False\n",
    "    for layer in model.children():\n",
    "        layer.apply(set_untrainable)\n",
    "    model.fc = nn.Linear(512, 2)\n",
    "    model.cuda()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "包裝器“with torch.no_grad（）”暫時將所有requires_grad標誌設置為false。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, loader, train):\n",
    "    load_path = './ckpt/'\n",
    "    model.load_state_dict(torch.load(load_path+'model.ckpt'))\n",
    "    train.load_state_dict(torch.load(load_path+'ts.ckpt')) \n",
    "#     model = model.eval()\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    start_time = time.time()\n",
    "    for x, y in loader:\n",
    "        with torch.no_grad():\n",
    "            x_var = x.cuda()\n",
    "\n",
    "            scores = model(x_var)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    print('duration = %s' % timedelta(seconds=time.time() - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "記得在測試時，要利用.unsqueeze(0)把size前面多加一個維度，也就是sample個數為1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, img_dir):\n",
    "    load_path = './ckpt/'\n",
    "    model.load_state_dict(torch.load(load_path+'model.ckpt'))\n",
    "    model.eval()\n",
    "    \n",
    "    img_path = Image.open(img_dir)\n",
    "    print(img_path.size) #記得要印出Image開啟的圖片尺寸要用size, 而tensor的尺寸才用size()\n",
    "    print(type(img_path))\n",
    "\n",
    "    # Load input\n",
    "    input_A = preprocess(img_path)\n",
    "    print(input_A.size())\n",
    "    input_B = preprocess(img_path).unsqueeze(0)\n",
    "    print(input_B.size())\n",
    "    with torch.no_grad():\n",
    "        x_var = input_B.cuda()\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        print(preds.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 500)\n",
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "model = resnet34()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=1e-2)\n",
    "\n",
    "# #訓練\n",
    "# train(model, tran_loader,val_loader, loss_fn, optimizer, num_epochs=1)\n",
    "# #測試\n",
    "# check_accuracy(model, test_loader, optimizer)\n",
    "\n",
    "#DEMO一張圖\n",
    "test(model,'cat.1106.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
